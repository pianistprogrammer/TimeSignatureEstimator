{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0697668f-3e5f-4e33-8df6-16c6eaa63c9c",
   "metadata": {},
   "source": [
    "This notebook demonstrates the use of a genetic algorithm to optimize the weights for weighted voting in ensemble voting for time signature detection.\n",
    "\n",
    "Introduction:\n",
    "- Ensemble voting is a technique that combines the predictions of multiple models to make a final decision.\n",
    "- In this notebook, we focus on time signature detection, which is the process of determining the time signature of a musical piece.\n",
    "- We use a weighted voting approach, where each model's prediction is multiplied by a weight and then summed up to make the final decision.\n",
    "- The genetic algorithm is employed to find the optimal weights that maximize the accuracy of the ensemble voting system.\n",
    "\n",
    "Usage:\n",
    "- Before running the code, make sure you have the necessary dependencies installed.\n",
    "- The code assumes that you have a dataset of labeled musical pieces for training and testing.\n",
    "- Adjust the hyperparameters and settings according to your specific needs.\n",
    "- Run the code cells sequentially to train the models, optimize the weights, and evaluate the ensemble voting system.\n",
    "- The results and performance metrics will be displayed in the output.\n",
    "\n",
    "Note: This code is provided as a starting point and can be customized and extended for different ensemble voting tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e2517-157d-4528-842a-b03564da426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to install the geneticalgorithm package\n",
    "# uncomment the following line to install the package\n",
    "# !pip install geneticalgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b3f4b0-643e-4d62-835c-d8dab98f5bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import glob\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "\n",
    "plt.rcParams.update({'font.size':20})\n",
    "\n",
    "num_classes = 2  # or 4, depending on the data you're working with\n",
    "\n",
    "csv_test_files = {\n",
    "    'cnn': f\"Models/Mfcc/{num_classes}-CLASSES/test/agg/cnn_mfcc_{num_classes}_cls_test_ensemble_agg.csv\",\n",
    "    'crnn': f\"Models/Mfcc/{num_classes}-CLASSES/test/agg/crnn_mfcc_{num_classes}_cls_test_ensemble_agg.csv\",\n",
    "    'resnet': f\"Models/Mfcc/{num_classes}-CLASSES/test/agg/resnet_mfcc_{num_classes}_cls_test_ensemble_agg.csv\",\n",
    "    'resnetlstm': f\"Models/Mfcc/{num_classes}-CLASSES/test/agg/resnetlstm_mfcc_{num_classes}_cls_test_ensemble_agg.csv\",\n",
    "    'svm': f\"Models/Mfcc/{num_classes}-CLASSES/test/agg/SVM_mfcc_{num_classes}_cls_test_ensemble_agg.csv\",\n",
    "    'knn': f\"Models/Mfcc/{num_classes}-CLASSES/test/agg/KNN_mfcc_{num_classes}_cls_test_ensemble_agg.csv\",\n",
    "    'naive': f\"Models/Mfcc/{num_classes}-CLASSES/test/agg/Naive_Bayes_mfcc_{num_classes}_cls_test_ensemble_agg.csv\",\n",
    "    'forest': f\"Models/Mfcc/{num_classes}-CLASSES/test/agg/R-Forest_mfcc_{num_classes}_cls_test_ensemble_agg.csv\"\n",
    "}\n",
    "\n",
    "\n",
    "csv_val_files = {\n",
    "    'cnn': f\"Models/Mfcc/{num_classes}-CLASSES/val/agg/cnn_mfcc_{num_classes}_cls_val_ensemble_agg.csv\",\n",
    "    'crnn': f\"Models/Mfcc/{num_classes}-CLASSES/val/agg/crnn_mfcc_{num_classes}_cls_val_ensemble_agg.csv\",\n",
    "    'resnet': f\"Models/Mfcc/{num_classes}-CLASSES/val/agg/resnet_mfcc_{num_classes}_cls_val_ensemble_agg.csv\",\n",
    "    'resnetlstm': f\"Models/Mfcc/{num_classes}-CLASSES/val/agg/resnetlstm_mfcc_{num_classes}_cls_val_ensemble_agg.csv\",\n",
    "    'svm': f\"Models/Mfcc/{num_classes}-CLASSES/val/agg/SVM_mfcc_{num_classes}_cls_val_ensemble_agg.csv\",\n",
    "    'knn': f\"Models/Mfcc/{num_classes}-CLASSES/val/agg/KNN_mfcc_{num_classes}_cls_val_ensemble_agg.csv\",\n",
    "    'naive': f\"Models/Mfcc/{num_classes}-CLASSES/val/agg/Naive_Bayes_mfcc_{num_classes}_cls_val_ensemble_agg.csv\",\n",
    "    'forest': f\"Models/Mfcc/{num_classes}-CLASSES/val/agg/R-Forest_mfcc_{num_classes}_cls_val_ensemble_agg.csv\"\n",
    "}\n",
    "\n",
    "# Test files becomes our training files for the genetic algorithm\n",
    "csv_files_train = [\n",
    "    csv_test_files['svm'], csv_test_files['cnn'], csv_test_files['knn'], \n",
    "    csv_test_files['resnetlstm'], csv_test_files['naive'], csv_test_files['forest'], \n",
    "    csv_test_files['crnn'], csv_test_files['resnet']\n",
    "]\n",
    "\n",
    "# Validation files becomes our test files for the genetic algorithm\n",
    "csv_files_test = [\n",
    "    csv_test_files['svm'], csv_test_files['cnn'], csv_test_files['knn'], \n",
    "    csv_test_files['resnetlstm'], csv_test_files['naive'], csv_test_files['forest'], \n",
    "    csv_test_files['crnn'], csv_test_files['resnet']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02961230-cb5b-4c9b-a1b5-4f4fbd878406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_csv_files(csv_files):\n",
    "    # Sort the CSV files by the `file_name` column in ascending order\n",
    "    sorted_csv_files = sorted(csv_files, key=lambda f: f.split('/')[-1])\n",
    "\n",
    "    # Iterate over the sorted CSV files\n",
    "    for csv_file in sorted_csv_files:\n",
    "\n",
    "        # Read the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        # Sort the DataFrame by the `file_name` column in ascending order\n",
    "        df = df.sort_values(by=['file_name'], ascending=True)\n",
    "\n",
    "        # Write the sorted DataFrame to the same CSV file\n",
    "        df.to_csv(csv_file, index=False)\n",
    "\n",
    "def create_grouped_df(csv_files):\n",
    "    grouped_df = pd.DataFrame()\n",
    "\n",
    "    for i, file in enumerate(csv_files):\n",
    "        df = pd.read_csv(file)\n",
    "        model_name = file.split(\"/\")[-1].split(\"_\")[0]  # Extract the model name from the file path\n",
    "\n",
    "        # Select the desired columns and rename them with the model name as a suffix\n",
    "        df_selected = df[['file_name', 'softmax_output', 'predictions']]\n",
    "        df_selected.columns = ['file_name', f'{model_name}_softmax_output', f'{model_name}_predictions']\n",
    "\n",
    "        if grouped_df.empty:\n",
    "            grouped_df = df_selected\n",
    "        else:\n",
    "            # Merge the selected columns with the existing grouped_df DataFrame\n",
    "            grouped_df = pd.merge(grouped_df, df_selected, on='file_name')\n",
    "\n",
    "    # Include the 'true_label' column\n",
    "    df_true_label = pd.read_csv(csv_files[0])  # Read the first CSV file to extract the 'true_label' column\n",
    "    grouped_df = pd.merge(grouped_df, df_true_label[['file_name', 'true_label']], on='file_name')\n",
    "\n",
    "    # Group the data by 'file_name' and select the first occurrence of each file name\n",
    "    grouped_df = grouped_df.groupby('file_name').first().reset_index()\n",
    "\n",
    "    return grouped_df\n",
    "\n",
    "def preprocess_softmax(df, softmax_columns):\n",
    "    softmax_arrays = []\n",
    "    for col in softmax_columns:\n",
    "        softmax_arrays.append(np.array([ast.literal_eval(val) for val in df[col]]))\n",
    "    return softmax_arrays\n",
    "\n",
    "def calculate_weighted_sum(df, softmax_arrays, weights):\n",
    "    weighted_sums = np.zeros((len(df), len(softmax_arrays[0][0])))\n",
    "    for i, prob in enumerate(softmax_arrays):\n",
    "        weighted_sums += prob * weights[i]\n",
    "    return weighted_sums\n",
    "\n",
    "def get_ensemble_predictions(weighted_sums):\n",
    "    return np.argmax(weighted_sums, axis=1)\n",
    "\n",
    "def evaluate_predictions(true_labels, ensemble_predictions):\n",
    "    report = classification_report(true_labels, ensemble_predictions, output_dict=True)\n",
    "    return report['accuracy']\n",
    "\n",
    "def weighted_voting(df, softmax_columns, weights, return_labels=False):\n",
    "    if not softmax_columns:\n",
    "        raise ValueError(\"No softmax columns found in the DataFrame.\")\n",
    "    \n",
    "    softmax_arrays = preprocess_softmax(df, softmax_columns)\n",
    "    weighted_sums = calculate_weighted_sum(df, softmax_arrays, weights)\n",
    "    ensemble_predictions = get_ensemble_predictions(weighted_sums)\n",
    "    \n",
    "    if return_labels:\n",
    "        true_labels = df['true_label'].tolist()\n",
    "        return ensemble_predictions, true_labels\n",
    "    else:\n",
    "        df['weighted'] = ensemble_predictions\n",
    "        return df\n",
    "\n",
    "\n",
    "def weighted_ensemble_voting_with_accuracy_list(df, softmax_columns, weights):\n",
    "    if not softmax_columns:\n",
    "        raise ValueError(\"No softmax columns found in the DataFrame.\")\n",
    "    \n",
    "    true_labels = df['true_label'].tolist()\n",
    "    softmax_arrays = preprocess_softmax(df, softmax_columns)\n",
    "    \n",
    "    accuracy_list = []\n",
    "    \n",
    "    for weight_set in weights:\n",
    "        weighted_sums = calculate_weighted_sum(df, softmax_arrays, weight_set)\n",
    "        ensemble_predictions = get_ensemble_predictions(weighted_sums)\n",
    "        accuracy = evaluate_predictions(true_labels, ensemble_predictions)\n",
    "        accuracy_list.append(accuracy)\n",
    "    \n",
    "    return accuracy_list\n",
    "\n",
    "def calculate_accuracy(predictions, true_labels):\n",
    "    correct = 0\n",
    "    total = len(predictions)\n",
    "    for pred, true_label in zip(predictions, true_labels):\n",
    "        if pred == true_label:\n",
    "            correct += 1\n",
    "    accuracy = correct / total\n",
    "    return 100 - accuracy\n",
    "\n",
    "def evaluate_weights(weights):\n",
    "    predictions, true_labels = weighted_voting(df, softmax_columns, weights, return_labels=True)\n",
    "    accuracy = calculate_accuracy(predictions, true_labels)\n",
    "    return accuracy\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title, normalize=False,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print(\"Confusion matrix without normalization\")\n",
    "        \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j,i, cm[i, j], \n",
    "                 horizontalalignment=\"center\", \n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True Meter\")\n",
    "    plt.xlabel(\"Predicted Meter\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef74ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of predictions columns\n",
    "sort_csv_files(csv_files_train)\n",
    "df = create_grouped_df(csv_files_train)\n",
    "test_df = create_grouped_df(csv_files_test)\n",
    "softmax_columns = [col for col in df.columns if col.endswith('_softmax_output')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c807b84",
   "metadata": {},
   "source": [
    "The following code implements the Genetic Algorithm (GA) for optimizing the weights in the ensemble voting system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09aade2-e341-42dc-9854-9e4bff2cf684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimization parameters\n",
    "varbound = np.array([[0, 1]] * 8) # Define the lower and upper bounds for the weights\n",
    "\n",
    "algorithm_param = {'max_num_iteration': 100,\n",
    "                   'population_size': 100,\n",
    "                   'mutation_probability': 0.6,\n",
    "                   'elit_ratio': 0.01,\n",
    "                   'crossover_probability': 0.2,\n",
    "                   'parents_portion': 0.5,\n",
    "                   'crossover_type': 'uniform',\n",
    "                   'max_iteration_without_improv': None}\n",
    "\n",
    "# Run the optimization process 50 times\n",
    "num_runs = 50\n",
    "optimized_weights_array = []\n",
    "\n",
    "for _ in range(num_runs):\n",
    "    # Initialize and run the genetic algorithm\n",
    "    model = ga(function=evaluate_weights,\n",
    "               dimension=8,\n",
    "               variable_type='real',\n",
    "               variable_boundaries=varbound,\n",
    "               algorithm_parameters=algorithm_param,\n",
    "               function_timeout=1000200)\n",
    "    model.run()\n",
    "\n",
    "    # Store the optimized weights in an array\n",
    "    optimized_weights_array.append(model.output_dict['variable'])\n",
    "\n",
    "# Convert the list of arrays to a numpy array\n",
    "optimized_weights_array = np.array(optimized_weights_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f809e0-e81d-4427-9a39-3ac34fdb84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names =['SVM', 'CNN', 'KNN','RES-LSTM', 'NB', 'RF',  'CRNN', 'RESNET'] \n",
    "num_weights = len(model_names)\n",
    "\n",
    "# Plot heatmap to visualize similarity between weights across runs\n",
    "plt.figure(figsize=(2070/100, 1570/100)) # Set the figure size to 30x30 inches\n",
    "plt.imshow(optimized_weights_array, cmap='viridis', aspect='auto')\n",
    "plt.xticks(ticks=np.arange(num_weights), labels=model_names)  # Set the fontsize for xticks\n",
    "plt.colorbar(label='Value')  # Set the fontsize for colorbar\n",
    "plt.xlabel('Models')  # Increase the xlabel fontsize\n",
    "plt.ylabel('Runs')  # Increase the ylabel fontsize\n",
    "\n",
    "plt.savefig('heatmap.png', dpi=200)  # Save the figure with 200 dpi\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4fe6db-aa56-4534-829e-c7d147021c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the weights for the weighted ensemble\n",
    "# pick one from the 50 runs\n",
    "weights = [0.01411482, 0.33084206, 0.51650582, 0.57955419, 0.12583674, 0.38093341, 0.16874136, 0.79187015]\n",
    "\n",
    "# Use the weightedEnsembleVoting method to get ensemble predictions\n",
    "weighted_df = weighted_voting(test_df, softmax_columns, weights, return_labels=False)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(weighted_df['true_label'], weighted_df['weighted'])\n",
    "    \n",
    "# Create the title with the model name\n",
    "title = f\"\\nCM | MFCC | Weighted-Ensemble | {num_classes} CLASSES\\n\"\n",
    "\n",
    "# Create the class labels\n",
    "if num_classes == 2:\n",
    "    classes = ['FOUR', 'THREE']\n",
    "elif num_classes == 4:\n",
    "    classes = ['FOUR', 'THREE', 'FIVE', 'SEVEN']\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=classes, title=title)\n",
    "plt.show()\n",
    "    \n",
    "print(classification_report(weighted_df['true_label'], weighted_df['weighted'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2923f0-6965-41b5-8f9b-2be2ef4b4066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: Calculate accuracy for each set of optimized weights\n",
    "# Initialize list to store accuracy values for each set of weights\n",
    "accuracy_results = []\n",
    "\n",
    "# Iterate over each set of weights\n",
    "for weights_set in optimized_weights_array:\n",
    "    # Use the weightedTestVoting method to get ensemble predictions and calculate accuracy\n",
    "    accuracy = weighted_ensemble_voting_with_accuracy_list(test_df, softmax_columns, [weights_set])\n",
    "    accuracy_results.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9e9b34-9c73-43bc-a86a-3d94ddad0f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_array = np.array(accuracy_results)\n",
    "\n",
    "# Calculate standard deviation, minimum, maximum, and mean\n",
    "std_deviation = np.std(accuracy_array)\n",
    "minimum = np.min(accuracy_array)\n",
    "maximum = np.max(accuracy_array)\n",
    "mean = np.mean(accuracy_array)\n",
    "\n",
    "print(\"Standard Deviation:\", std_deviation)\n",
    "print(\"Minimum:\", minimum)\n",
    "print(\"Maximum:\", maximum)\n",
    "print(\"Mean:\", mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
